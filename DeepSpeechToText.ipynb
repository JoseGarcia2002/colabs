{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5zOBEkcEAKqe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseGarcia2002/colabs/blob/main/DeepSpeechToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KUlO4oiA8CM"
      },
      "source": [
        "# README\n",
        "\n",
        "* [DeepSpeech](https://github.com/mozilla/DeepSpeech) is an \"open-source Speech-To-Text engine, using a model trained by machine learning techniques based on Baidu's Deep Speech [research paper](https://arxiv.org/abs/1412.5567)\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "Time required: a few minutes"
      ],
      "metadata": {
        "id": "5zOBEkcEAKqe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OAYywPHApuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e15170-4cc5-473a-bd94-b345067a8631"
      },
      "source": [
        "#@title Default title text\n",
        "!apt-get install -qq sox\n",
        "!pip install -q deepspeech-gpu==0.6.1 youtube-dl\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n",
        "!tar xvfz deepspeech-0.6.1-models.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../7-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "\u001b[K     |████████████████████████████████| 18.7 MB 17.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 44.8 MB/s \n",
            "\u001b[?25h--2022-09-13 13:42:51--  https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/f29e6300-33cd-11ea-8523-3fc40b31be9a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220913%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220913T134251Z&X-Amz-Expires=300&X-Amz-Signature=ef272b0435dc2ff478768d56037c15379c29a41b1e9bd8580df023b756b8f92b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.6.1-models.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-13 13:42:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/60273704/f29e6300-33cd-11ea-8523-3fc40b31be9a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220913%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220913T134251Z&X-Amz-Expires=300&X-Amz-Signature=ef272b0435dc2ff478768d56037c15379c29a41b1e9bd8580df023b756b8f92b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.6.1-models.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1229020343 (1.1G) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.6.1-models.tar.gz’\n",
            "\n",
            "deepspeech-0.6.1-mo 100%[===================>]   1.14G  9.39MB/s    in 5m 53s  \n",
            "\n",
            "2022-09-13 13:48:44 (3.33 MB/s) - ‘deepspeech-0.6.1-models.tar.gz’ saved [1229020343/1229020343]\n",
            "\n",
            "._deepspeech-0.6.1-models\n",
            "deepspeech-0.6.1-models/\n",
            "deepspeech-0.6.1-models/._lm.binary\n",
            "deepspeech-0.6.1-models/lm.binary\n",
            "deepspeech-0.6.1-models/._output_graph.pbmm\n",
            "deepspeech-0.6.1-models/output_graph.pbmm\n",
            "deepspeech-0.6.1-models/._output_graph.pb\n",
            "deepspeech-0.6.1-models/output_graph.pb\n",
            "deepspeech-0.6.1-models/._trie\n",
            "deepspeech-0.6.1-models/trie\n",
            "deepspeech-0.6.1-models/output_graph.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upload video"
      ],
      "metadata": {
        "id": "21-ASPyLBG-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "fn = list(uploaded.keys())[0]\n",
        "print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "t5U-FYp_A_uA",
        "outputId": "5e7e1837-0b3f-4f1d-b97a-0739c5c798a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1dec4b52-0f6d-460a-884f-d2a2d863fa7d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1dec4b52-0f6d-460a-884f-d2a2d863fa7d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95JShwLGB43D"
      },
      "source": [
        "## Demo"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ef_aVy-LO26C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert file into wav\n",
        "!ffmpeg -i \"$fn\" output_audio.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3jQulUBPV3",
        "outputId": "1c6bfa70-f795-43f4-b83a-e07d6f82335f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;35m[mp3 @ 0x55b105436000] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, mp3, from 'barackobamatransitionaddress1.mp3':\n",
            "  Metadata:\n",
            "    comment         : Remixed and Mastered by Michael E. Eidenmuller\n",
            "    genre           : Speech\n",
            "    artist          : Barack Obama\n",
            "    title           : First President-Elect Weekly Transition Address\n",
            "    encoded_by      : Michael E. Eidenmuller\n",
            "    copyright       : 2009\n",
            "    TOPE            : Change.gov\n",
            "    publisher       : AmericanRhetoric.com\n",
            "    date            : 2008\n",
            "  Duration: 00:03:30.69, start: 0.000000, bitrate: 80 kb/s\n",
            "    Stream #0:0: Audio: mp3, 22050 Hz, stereo, s16p, 80 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'output_audio.wav':\n",
            "  Metadata:\n",
            "    ICMT            : Remixed and Mastered by Michael E. Eidenmuller\n",
            "    IGNR            : Speech\n",
            "    IART            : Barack Obama\n",
            "    INAM            : First President-Elect Weekly Transition Address\n",
            "    ITCH            : Michael E. Eidenmuller\n",
            "    ICOP            : 2009\n",
            "    TOPE            : Change.gov\n",
            "    publisher       : AmericanRhetoric.com\n",
            "    ICRD            : 2008\n",
            "    ISFT            : Lavf57.83.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, stereo, s16, 705 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 pcm_s16le\n",
            "size=   18147kB time=00:03:30.67 bitrate= 705.6kbits/s speed= 785x    \n",
            "video:0kB audio:18146kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001550%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZwM0GtmA7mX",
        "outputId": "d626c2c4-1e63-4895-f612-aa1709bd53d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio output_audio.wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from file deepspeech-0.6.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.1-0-g3df20fe\n",
            "2022-09-13 14:21:23.404964: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-09-13 14:21:23.405922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2022-09-13 14:21:23.477552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-13 14:21:23.478177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-09-13 14:21:23.478201: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
            "2022-09-13 14:21:23.478258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-13 14:21:23.478935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-13 14:21:23.479550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2022-09-13 14:22:44.613867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-09-13 14:22:44.613939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2022-09-13 14:22:44.613955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2022-09-13 14:22:44.614156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-13 14:22:44.614819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-13 14:22:44.615382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-13 14:22:44.615893: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-09-13 14:22:44.615940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14228 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loaded model in 81.2s.\n",
            "Loading language model from files deepspeech-0.6.1-models/lm.binary deepspeech-0.6.1-models/trie\n",
            "Loaded language model in 0.000216s.\n",
            "Warning: original sample rate (22050) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
            "Running inference.\n",
            "on tuesday american stood in line this stretched round schools and churches and numbers this nation has never seen it in matter would they were or where they came from what they look like for what party they go on to they came out and cast their ballot because they believed that in this country bardesanes not written for us but by us we should all take pride in the fact that we want it again to play for the world the power of artemis and reaffirmed that the great american idea of that this of the nation where anything is possible this week i foreseen bush who brace the flowered his full apartness as since in this period of transition michel i will forward meeting with him and the first lady on monday to begin that process this peasant recognition that here in america we can compete vigorously in elections and shall in each other's ideas yet come together in service of a common purpose once the voting is done and that is particularly important at a moment when we face the most serious challenges of our lifetime yesterday we will go to more sobering those bethesda of our economy the two hundred forty thousand jobs lost in october mark the ten consecutive mon that our commis shed jobs in oral we bought dealing one point two million jobs this year and more than ten million americans are now unemployed tens of millions of families are struggling to figure out how to pay the bills in fainter homes the stories are in urging reminder the we are taking the greatest economic shall inger lifetime and we must act cicely to roll them in the way of these disturbing reports i met with members of my transition economic advisory board who will help guide the work of my transition seem in developing a strong set of holes to respond to this crisis that we must recognize that we only have one president at a time and the present bush is believer or government i want to insure that we have the grumbling on january twentieth because we don't have a moment's aloose we discussed the several demosthenian shall nesting or economy that keeper areas on which to focus in the days and weeks ahead to ease the critic rises helaman families and restored rode and property first we need a resurgance mill glass that i vestiaire efforts to create jobs and provides williston the washing the paycheck strait and the life saving disappear then will address the spreading impact of the financial rises on other sectors of our economy and in shore that the rest planeteers his working tiflis financial markets while protecting tax payers helping home owners and not unduly rewarding the management of financial firms that are receiving government assistance finally we will move forward with a set of policies that will grow our middle class and strengthen our economy in the long term we can for the wave on moving forward on the keeper or as that i identified during the campaign including clean energy health care education and tax relief from middle class families let me close my saying i do not under estimate the enormity of the task belisaire taken some major actions to date than we will need further actions during this transition and solomons some choices will be difficult but america is a strong and resilient country i know that we will succeed if we put aside partisanship and work together as one nation and that is what i intend to do\n",
            "Inference took 51.018s for 290.340s audio file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3nKu11iCnKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}